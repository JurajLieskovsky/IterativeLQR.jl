var documenterSearchIndex = {"docs":
[{"location":"guide/#Getting-started","page":"Getting started","title":"Getting started","text":"","category":"section"},{"location":"guide/#Installation","page":"Getting started","title":"Installation","text":"The package can be added to your project using the command\n\n] add https://github.com/JurajLieskovsky/IterativeLQR.jl.git\n\nin your REPL. For usage, we recommend taking a look at one of the [examples](@repo/examples/cartpole/swing_up.jl].","category":"section"},{"location":"guide/#Examples","page":"Getting started","title":"Examples","text":"To run the examples we recommend cloning main repository\n\ngit clone git@github.com:JurajLieskovsky/IterativeLQR.jl.git IterativeLQR\n\nNavigating to the IterativeLQR/examples folder and starting Julia\n\ncd IterativeLQR/examples\njulia\n\nIn the REPL, activating and instantiating the environment\n\nusing Pkg\nPkg.activate(\".\")\nPkg.instantiate()\n\nRunning one of the examples\n\ninclude(\"cartpole/swing_up.jl\")","category":"section"},{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/#Algorithm","page":"Reference","title":"Algorithm","text":"","category":"section"},{"location":"reference/#Workset","page":"Reference","title":"Workset","text":"","category":"section"},{"location":"reference/#Regularization","page":"Reference","title":"Regularization","text":"","category":"section"},{"location":"reference/#IterativeLQR.backward_pass!-Tuple{IterativeLQR.Workset}","page":"Reference","title":"IterativeLQR.backward_pass!","text":"Perform the backward pass of the algorithm. Mainly, produce the the terms d and K of the policy update as well as the expected improvement Δv.\n\n\n\n\n\n","category":"method"},{"location":"reference/#IterativeLQR.cost_regularization!-Tuple{IterativeLQR.Workset, Real, Symbol}","page":"Reference","title":"IterativeLQR.cost_regularization!","text":"Regularize the hessians of the running cost l and final cost Φ. (multithreaded)\n\n\n\n\n\n","category":"method"},{"location":"reference/#IterativeLQR.differentiation!-Tuple{IterativeLQR.Workset, Function, Function, Function, Bool}","page":"Reference","title":"IterativeLQR.differentiation!","text":"Produce partial derivatives of the system's dynamics f and costs l and Φ that are required for the backward pass of the algorithm. (multithreaded)\n\n\n\n\n\n","category":"method"},{"location":"reference/#IterativeLQR.differentiation!-Tuple{IterativeLQR.Workset, Function, Function, Function, Function, Bool}","page":"Reference","title":"IterativeLQR.differentiation!","text":"Produce partial derivatives of the system's dynamics f and costs l and Φ   that are required for the backward pass of the algorithm. Also transform them   to the surface of the state manifold using coordinate jacobians. (multithreaded)\n\n\n\n\n\n","category":"method"},{"location":"reference/#IterativeLQR.forward_pass!-Tuple{IterativeLQR.Workset, Function, Function, Function, Function, Real}","page":"Reference","title":"IterativeLQR.forward_pass!","text":"Perform the forward pass of the algorithm, i.e. produce a candidate trajectory x, u.\n\n\n\n\n\n","category":"method"},{"location":"reference/#IterativeLQR.iLQR!-Tuple{IterativeLQR.Workset, Vararg{Function, 6}}","page":"Reference","title":"IterativeLQR.iLQR!","text":"Optimize the trajectory of a system with in-place dynamics! for the running_cost and final_cost on a horizon of length N. The number of the system's states nx and inputs nu as well as the horizon's length N must be compatible with the workset which is constructed using these quantities.\n\nFunctions dynamics_diff!, running_cost_diff!, and final_cost_diff! are used to calculate partial derivatives. They can either calculate each partial derivatives with respect to x and u separately:\n\ndynamics_diff!(fx, fu, x, u, k),\nrunning_cost_diff!(lx, lu, lxx, lxu, luu, x, u, k),\nfinal_cost_diff!(Φx, Φxx, x, k)\n\nor in a stacked form:\n\ndynamics_diff!(∇f, x, u, k),\nrunning_cost_diff!(∇l, ∇2l, x, u, k),\nfinal_cost_diff!(Φx, Φxx, x, k).\n\nIf the stacked form is used, set the keyword argument stacked_derivatives to True.\n\nIf the state of the system lies on a manifold, the keyword arguments state_difference and coordinate_jacobian must be supplied. Also ndx!=nx must have been used in the construction of workset.\n\nTo re-use the nominal control policy from a previous solve (for example in MPC applications) set rollout=:partial. The default rollout=:full uses the nominal inputs in feedforward manner to produce the states of the nominal trajectory.\n\nDuring the optimization, printout into the console can be switched of using by setting verbose=false. Instead of printing (or in addition to) information about each iteration can be stored in a dataframe::DataFrames.DataFrame by setting logging=true. If set true the dataframe is the only output of the function.\n\nQuantities in the workset can be plotted live using the plotting_callback keyword argument which expects a function with the signature plotting_callback(workset). It is called once after the intial rollout and then after every succesful iteration.\n\n\n\n\n\n","category":"method"},{"location":"reference/#IterativeLQR.iteration_dataframe-Tuple{}","page":"Reference","title":"IterativeLQR.iteration_dataframe","text":"Create a data frame for logging information about the iterations of the algorithm.\n\n\n\n\n\n","category":"method"},{"location":"reference/#IterativeLQR.log_iteration!-NTuple{13, Any}","page":"Reference","title":"IterativeLQR.log_iteration!","text":"Log information into the data frame about the iterations of the algorithm.\n\n\n\n\n\n","category":"method"},{"location":"reference/#IterativeLQR.print_iteration!-NTuple{13, Any}","page":"Reference","title":"IterativeLQR.print_iteration!","text":"Print information about the current iteration.\n\n\n\n\n\n","category":"method"},{"location":"reference/#IterativeLQR.trajectory_rollout!-Tuple{IterativeLQR.Workset, Function, Function, Function}","page":"Reference","title":"IterativeLQR.trajectory_rollout!","text":"Roll-out the states x̄ₖ of the nominal trajectory from the initial state x̃₁ and nominal inputs ūₖ. Also evaluate the running costs lₖ in multiple threads and the final cost Φ. \n\n\n\n\n\n","category":"method"},{"location":"reference/#IterativeLQR.BackwardPassWorkset","page":"Reference","title":"IterativeLQR.BackwardPassWorkset","text":"Struct containing quantities used exclusively in the backward pass of the algorithm.\n\n\n\n\n\n","category":"type"},{"location":"reference/#IterativeLQR.CoordinateJacobians","page":"Reference","title":"IterativeLQR.CoordinateJacobians","text":"Struct containing coordinate jacobians Eₖ.\n\n\n\n\n\n","category":"type"},{"location":"reference/#IterativeLQR.CostDerivatives","page":"Reference","title":"IterativeLQR.CostDerivatives","text":"Struct containing partial derivatives of the running cost l and the final cost Φ.\n\n\n\n\n\n","category":"type"},{"location":"reference/#IterativeLQR.DynamicsDerivatives","page":"Reference","title":"IterativeLQR.DynamicsDerivatives","text":"Struct containing partial derivatives of the system's dyanamics f.\n\n\n\n\n\n","category":"type"},{"location":"reference/#IterativeLQR.PolicyUpdate","page":"Reference","title":"IterativeLQR.PolicyUpdate","text":"Struct containing terms dₖ and Kₖ of the policy update δuₖ(δxₖ) = dₖ + Kₖδxₖ.\n\n\n\n\n\n","category":"type"},{"location":"reference/#IterativeLQR.Trajectory","page":"Reference","title":"IterativeLQR.Trajectory","text":"Struct containing a trajectory xₖ, uₖ of the controlled system (including costs).\n\n\n\n\n\n","category":"type"},{"location":"reference/#IterativeLQR.Workset","page":"Reference","title":"IterativeLQR.Workset","text":"Struct containing the nominal trajectory (current the most optimal) as well as all internal quantities of the algorithm.\n\n\n\n\n\n","category":"type"},{"location":"reference/#IterativeLQR.Workset-Union{Tuple{Int64, Int64, Int64}, NTuple{4, Int64}, Tuple{T}} where T","page":"Reference","title":"IterativeLQR.Workset","text":"Create a Workset for the trajectory optimization problem.\n\nArguments\n\nnx: number of states\nnu: number of inputs\nN: length of the optimizations horizon \nndx: number of independent states (defaults to nx)\n\nReturns\n\n\n\n\n\n","category":"method"},{"location":"reference/#IterativeLQR.active_trajectory-Tuple{IterativeLQR.Workset}","page":"Reference","title":"IterativeLQR.active_trajectory","text":"Access the active trajectory\n\n\n\n\n\n","category":"method"},{"location":"reference/#IterativeLQR.nominal_trajectory-Tuple{IterativeLQR.Workset}","page":"Reference","title":"IterativeLQR.nominal_trajectory","text":"Access the nominal trajectory\n\n\n\n\n\n","category":"method"},{"location":"reference/#IterativeLQR.set_initial_state!-Tuple{IterativeLQR.Workset, Vector}","page":"Reference","title":"IterativeLQR.set_initial_state!","text":"Set the initial state x̃₁.\n\n\n\n\n\n","category":"method"},{"location":"reference/#IterativeLQR.set_nominal_inputs!","page":"Reference","title":"IterativeLQR.set_nominal_inputs!","text":"Set the nominal inputs ūₖ.\n\n\n\n\n\n","category":"function"},{"location":"reference/#IterativeLQR.swap_trajectories!-Tuple{IterativeLQR.Workset}","page":"Reference","title":"IterativeLQR.swap_trajectories!","text":"Swap the nominal and active trajectory (without copying any data).\n\n\n\n\n\n","category":"method"},{"location":"reference/#IterativeLQR.eigenvalue_regularization!-Tuple{Any, Real}","page":"Reference","title":"IterativeLQR.eigenvalue_regularization!","text":"Regularizes H using the eigenvalue approach, so that all of its eigen values are >=δ.\n\n\n\n\n\n","category":"method"},{"location":"reference/#IterativeLQR.gmw_regularization!-Tuple{Any, Any}","page":"Reference","title":"IterativeLQR.gmw_regularization!","text":"Regularized H using the Gill-Murray-Wright modified Cholesky factorization.\n\n\n\n\n\n","category":"method"},{"location":"reference/#IterativeLQR.regularize!-Tuple{AbstractMatrix, Real, Symbol}","page":"Reference","title":"IterativeLQR.regularize!","text":"Regularizes the symmetric matrix H so that it is positive definite. The argument approach determines if an eigenvalue approach is taken eigenvalue_regularization! or the GMW modified Cholesky decomposition algorithm is used gmw_regularization!.\n\n\n\n\n\n","category":"method"},{"location":"#IterativeLQR.jl","page":"Home","title":"IterativeLQR.jl","text":"An implementation of the iterative linear-quadratic regulator (iLQR) with regularization by the way of minimal hessian modification. System's whose states lie on a manifold are supported through user supplied state difference and coordinate Jacobian functions.","category":"section"}]
}
